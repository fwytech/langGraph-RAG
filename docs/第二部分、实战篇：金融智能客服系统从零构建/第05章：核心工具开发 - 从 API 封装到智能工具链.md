# ç¬¬05ç« ï¼šæ ¸å¿ƒå·¥å…·å¼€å‘ - ä» API å°è£…åˆ°æ™ºèƒ½å·¥å…·é“¾

> **ç‰ˆæœ¬ä¿¡æ¯**
> - **LangChain**: 1.0.7+
> - **LangGraph**: 1.0.3+
> - **Pydantic**: 2.0+
> - **ç¼–å†™æ—¥æœŸ**: 2025-01-16
> - **ä½œè€…**: LangGraph-RAG Tutorial Team

---

## æœ¬ç« å¯¼è¯»

åœ¨å‰é¢çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å·²ç»å®Œæˆäº†é¡¹ç›®åˆå§‹åŒ–ï¼ˆç¬¬03ç« ï¼‰å’Œå‘é‡æ•°æ®åº“æ­å»ºï¼ˆç¬¬04ç« ï¼‰ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦å°†è¿™äº›ç‹¬ç«‹çš„ç»„ä»¶"æ­¦å™¨åŒ–"ï¼Œè®©å®ƒä»¬æˆä¸º LangGraph Agent å¯ä»¥è°ƒç”¨çš„**æ™ºèƒ½å·¥å…·**ã€‚

**æœ¬ç« æ ¸å¿ƒé—®é¢˜ï¼š**
- ğŸ¤” ä»€ä¹ˆæ˜¯ LangChain å·¥å…·ï¼ˆToolï¼‰ï¼Ÿä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿ
- ğŸ”§ å¦‚ä½•å°†æ™®é€šå‡½æ•°å°è£…ä¸º LangChain å·¥å…·ï¼Ÿ
- ğŸ“ å¦‚ä½•ç”¨ Pydantic å®ç°ç±»å‹å®‰å…¨çš„å‚æ•°éªŒè¯ï¼Ÿ
- ğŸ› ï¸ StructuredTool vs BaseTool vs @tool è£…é¥°å™¨ï¼Œå¦‚ä½•é€‰æ‹©ï¼Ÿ
- ğŸ¯ å¦‚ä½•å°è£… RAG æ£€ç´¢å™¨ä¸ºå¯è°ƒç”¨å·¥å…·ï¼Ÿ
- ğŸ”— å¦‚ä½•è®¾è®¡ LLM å®¢æˆ·ç«¯çš„ç»Ÿä¸€å°è£…ï¼Ÿ

**æœ¬ç« å°†å¸¦ä½ å®ç°ï¼š**
- âœ… ç†è§£ LangChain å·¥å…·ä½“ç³»æ¶æ„
- âœ… æŒæ¡ Pydantic BaseModel çš„å‚æ•°å®šä¹‰
- âœ… å®ç° RAG æ£€ç´¢å·¥å…·ï¼ˆ`naive_rag_tool.py`ï¼‰
- âœ… å®ç° LLM å®¢æˆ·ç«¯å°è£…ï¼ˆ`llm_client.py`ï¼‰
- âœ… ç†è§£å·¥å…·è°ƒç”¨çš„åº•å±‚æœºåˆ¶ï¼ˆFunction Callingï¼‰

**æŠ€æœ¯æ ˆå¿«é€Ÿé¢„è§ˆï¼š**

```
ğŸ“¦ æœ¬ç« æŠ€æœ¯æ ˆ
â”œâ”€â”€ ğŸ”§ å·¥å…·æ¡†æ¶ï¼šLangChain Tools (StructuredTool)
â”œâ”€â”€ ğŸ“ å‚æ•°éªŒè¯ï¼šPydantic v2 (BaseModel + Field)
â”œâ”€â”€ ğŸ¤– LLM å®¢æˆ·ç«¯ï¼šChatOpenAI (streaming=True)
â”œâ”€â”€ ğŸ”— å·¥å…·ç»‘å®šï¼šbind_tools() (OpenAI Function Calling)
â””â”€â”€ ğŸ› ï¸ æ£€ç´¢å·¥å…·ï¼šRAG Tool (ChromaDB + Retriever)
```

---

## 1. LangChain å·¥å…·ä½“ç³»æ·±åº¦è§£æ

### 1.1 ä»€ä¹ˆæ˜¯å·¥å…·ï¼ˆToolï¼‰ï¼Ÿ

åœ¨ LangChain ç”Ÿæ€ä¸­ï¼Œ**å·¥å…·ï¼ˆToolï¼‰** æ˜¯ Agent ä¸å¤–éƒ¨ä¸–ç•Œäº¤äº’çš„æ¡¥æ¢ã€‚

#### **ä¼ ç»Ÿ LLM vs å¸¦å·¥å…·çš„ LLM**

```mermaid
graph LR
    subgraph "ä¼ ç»Ÿ LLMï¼ˆå°é—­ç³»ç»Ÿï¼‰"
        User1[ç”¨æˆ·æé—®] --> LLM1[LLM]
        LLM1 --> Answer1[ç”Ÿæˆå›ç­”]
    end

    subgraph "å¸¦å·¥å…·çš„ LLMï¼ˆå¼€æ”¾ç³»ç»Ÿï¼‰"
        User2[ç”¨æˆ·æé—®] --> Agent[Agent]
        Agent --> Decide{éœ€è¦å¤–éƒ¨ä¿¡æ¯?}
        Decide -->|æ˜¯| Tool[è°ƒç”¨å·¥å…·]
        Tool --> Search[æœç´¢çŸ¥è¯†åº“]
        Search --> Result[è·å–ç»“æœ]
        Result --> Agent
        Decide -->|å¦| LLM2[LLM]
        Agent --> LLM2
        LLM2 --> Answer2[ç”Ÿæˆå›ç­”]
    end

    style Tool fill:#fff4e1
    style Search fill:#e1f5ff
```

**ç¤ºä¾‹å¯¹æ¯”ï¼š**

**åœºæ™¯ï¼šç”¨æˆ·è¯¢é—® "2024å¹´æˆ¿è´·åˆ©ç‡æ˜¯å¤šå°‘ï¼Ÿ"**

```python
# ä¼ ç»Ÿ LLMï¼ˆæ— å·¥å…·ï¼‰
user_query = "2024å¹´æˆ¿è´·åˆ©ç‡æ˜¯å¤šå°‘ï¼Ÿ"
response = llm.invoke(user_query)
print(response.content)
# è¾“å‡ºï¼šæŠ±æ­‰ï¼Œæˆ‘çš„çŸ¥è¯†æˆªæ­¢åˆ°2023å¹´4æœˆï¼Œæ— æ³•æä¾›2024å¹´çš„æ•°æ®ã€‚

# å¸¦å·¥å…·çš„ LLM
tools = [knowledge_base_search_tool]
llm_with_tools = llm.bind_tools(tools)

# Agent è‡ªåŠ¨æ¨ç†ï¼š
# 1. è¯†åˆ«éœ€è¦æŸ¥è¯¢çŸ¥è¯†åº“
# 2. è°ƒç”¨ knowledge_base_search_tool("2024å¹´æˆ¿è´·åˆ©ç‡")
# 3. è·å–ç»“æœï¼š"æ ¹æ®æœ€æ–°æ”¿ç­–ï¼Œ2024å¹´æˆ¿è´·åˆ©ç‡ä¸ºLPR+0.5%..."
# 4. åŸºäºç»“æœç”Ÿæˆå›ç­”

response = agent.invoke(user_query)
print(response.content)
# è¾“å‡ºï¼šæ ¹æ®æˆ‘è¡Œæœ€æ–°äº§å“æ‰‹å†Œï¼Œ2024å¹´ä¸ªäººä½æˆ¿è´·æ¬¾åˆ©ç‡ä¸ºLPR+0.5%ï¼Œ
#      é¦–å¥—æˆ¿å¯äº«å—LPR+0.3%çš„ä¼˜æƒ åˆ©ç‡ã€‚
```

---

### 1.2 å·¥å…·çš„æœ¬è´¨ï¼šå‡½æ•° + å…ƒæ•°æ®

åœ¨ LangChain ä¸­ï¼Œå·¥å…·ç”±ä¸‰éƒ¨åˆ†ç»„æˆï¼š

```python
# å·¥å…·çš„ä¸‰è¦ç´ 
tool = {
    "name": "knowledge_base_search",          # 1. å·¥å…·åç§°
    "description": "æœç´¢é‡‘èçŸ¥è¯†åº“è·å–äº§å“ä¿¡æ¯",  # 2. å·¥å…·æè¿°
    "parameters": {                            # 3. å‚æ•°å®šä¹‰
        "query": {
            "type": "string",
            "description": "ç”¨æˆ·çš„æŸ¥è¯¢é—®é¢˜"
        }
    },
    "function": lambda query: search(query)    # 4. å®é™…æ‰§è¡Œå‡½æ•°
}
```

**ä¸ºä»€ä¹ˆéœ€è¦å…ƒæ•°æ®ï¼Ÿ**

**åŸå› ï¼šLLM éœ€è¦ç†è§£"ä½•æ—¶"ä»¥åŠ"å¦‚ä½•"è°ƒç”¨å·¥å…·**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM çš„æ¨ç†è¿‡ç¨‹ï¼ˆåŸºäºå·¥å…·å…ƒæ•°æ®ï¼‰                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. ç”¨æˆ·é—®ï¼š"æˆ¿è´·åˆ©ç‡æ˜¯å¤šå°‘ï¼Ÿ"                              â”‚
â”‚                                                             â”‚
â”‚ 2. LLM åˆ†æå¯ç”¨å·¥å…·ï¼š                                       â”‚
â”‚    - knowledge_base_search: "æœç´¢é‡‘èçŸ¥è¯†åº“è·å–äº§å“ä¿¡æ¯"   â”‚
â”‚      â†’ åŒ¹é…ï¼è¿™ä¸ªå·¥å…·å¯ä»¥è·å–äº§å“ä¿¡æ¯                      â”‚
â”‚                                                             â”‚
â”‚ 3. LLM ç”Ÿæˆå·¥å…·è°ƒç”¨è¯·æ±‚ï¼š                                   â”‚
â”‚    {                                                        â”‚
â”‚      "tool": "knowledge_base_search",                       â”‚
â”‚      "arguments": {"query": "æˆ¿è´·åˆ©ç‡"}                     â”‚
â”‚    }                                                        â”‚
â”‚                                                             â”‚
â”‚ 4. æ‰§è¡Œå·¥å…· â†’ è¿”å›ç»“æœ â†’ LLM ç”Ÿæˆæœ€ç»ˆå›ç­”                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 1.3 LangChain 1.x å·¥å…·ç±»å‹å¯¹æ¯”

LangChain æä¾›ä¸‰ç§å·¥å…·å®šä¹‰æ–¹å¼ï¼š

| æ–¹å¼ | é€‚ç”¨åœºæ™¯ | å¤æ‚åº¦ | ç±»å‹å®‰å…¨ | æœ¬é¡¹ç›®é€‰æ‹© |
|------|----------|--------|----------|------------|
| **@tool è£…é¥°å™¨** | ç®€å•å‡½æ•° | â­ | âš ï¸ å¼± | âŒ |
| **StructuredTool** | ä¸­ç­‰å¤æ‚åº¦ | â­â­ | âœ… å¼ºï¼ˆPydanticï¼‰ | âœ… **é¦–é€‰** |
| **BaseTool å­ç±»** | é«˜åº¦è‡ªå®šä¹‰ | â­â­â­ | âœ… å¼º | âš ï¸ å¤‡é€‰ |

---

#### **æ–¹å¼1ï¼š@tool è£…é¥°å™¨ï¼ˆç®€å•ä½†ä¸å®‰å…¨ï¼‰**

```python
from langchain_core.tools import tool

@tool
def search_knowledge_base(query: str) -> str:
    """æœç´¢é‡‘èçŸ¥è¯†åº“è·å–äº§å“ä¿¡æ¯"""
    # å®ç°é€»è¾‘
    return "æŸ¥è¯¢ç»“æœ..."

# ä½¿ç”¨
result = search_knowledge_base.invoke({"query": "æˆ¿è´·åˆ©ç‡"})
```

**ä¼˜ç‚¹ï¼š**
- âœ… ä»£ç ç®€æ´ï¼ˆ1è¡Œè£…é¥°å™¨ï¼‰
- âœ… è‡ªåŠ¨ä»å‡½æ•°ç­¾åæå–å‚æ•°

**ç¼ºç‚¹ï¼š**
- âŒ æ— æ³•è‡ªå®šä¹‰å‚æ•°æè¿°ï¼ˆLLM åªèƒ½çœ‹åˆ°å‚æ•°å `query`ï¼‰
- âŒ ç±»å‹éªŒè¯å¼±ï¼ˆåªåœ¨è¿è¡Œæ—¶æ£€æŸ¥ï¼‰
- âŒ ä¸æ”¯æŒå¤æ‚å‚æ•°ï¼ˆå¦‚åµŒå¥—å¯¹è±¡ï¼‰

---

#### **æ–¹å¼2ï¼šStructuredToolï¼ˆæ¨èï¼‰**

```python
from langchain_core.tools import StructuredTool
from pydantic import BaseModel, Field

class KBQuery(BaseModel):
    query: str = Field(description="ç”¨æˆ·çš„æŸ¥è¯¢é—®é¢˜ï¼Œä¾‹å¦‚ï¼šæˆ¿è´·åˆ©ç‡æ˜¯å¤šå°‘")

def search_kb(query: str) -> str:
    """å®é™…æ‰§è¡Œå‡½æ•°"""
    return f"æŸ¥è¯¢'{query}'çš„ç»“æœ..."

tool = StructuredTool(
    name="knowledge_base_search",
    description="æœç´¢é‡‘èçŸ¥è¯†åº“è·å–äº§å“ä¿¡æ¯ï¼ŒåŒ…æ‹¬è´·æ¬¾ã€ä¿¡ç”¨å¡ã€ç†è´¢ç­‰",
    args_schema=KBQuery,  # Pydantic æ¨¡å‹
    func=search_kb
)
```

**ä¼˜ç‚¹ï¼š**
- âœ… **å¼ºç±»å‹éªŒè¯**ï¼ˆPydantic è‡ªåŠ¨éªŒè¯ï¼‰
- âœ… **è¯¦ç»†å‚æ•°æè¿°**ï¼ˆå¸®åŠ© LLM æ­£ç¡®è°ƒç”¨ï¼‰
- âœ… **æ”¯æŒå¤æ‚å‚æ•°**ï¼ˆåµŒå¥—å¯¹è±¡ã€åˆ—è¡¨ã€æšä¸¾ç­‰ï¼‰
- âœ… **IDE è‡ªåŠ¨è¡¥å…¨**ï¼ˆç±»å‹æç¤ºå®Œæ•´ï¼‰

**ç¼ºç‚¹ï¼š**
- âš ï¸ ä»£ç ç¨é•¿ï¼ˆéœ€å®šä¹‰ Pydantic æ¨¡å‹ï¼‰

---

#### **æ–¹å¼3ï¼šBaseTool å­ç±»ï¼ˆé«˜åº¦è‡ªå®šä¹‰ï¼‰**

```python
from langchain_core.tools import BaseTool
from pydantic import Field

class KnowledgeBaseSearchTool(BaseTool):
    name: str = "knowledge_base_search"
    description: str = "æœç´¢é‡‘èçŸ¥è¯†åº“è·å–äº§å“ä¿¡æ¯"

    kb_name: str = Field(description="çŸ¥è¯†åº“åç§°")  # å·¥å…·è‡ªèº«å±æ€§

    def _run(self, query: str) -> str:
        """åŒæ­¥æ‰§è¡Œ"""
        return f"åœ¨çŸ¥è¯†åº“ {self.kb_name} ä¸­æŸ¥è¯¢ '{query}'..."

    async def _arun(self, query: str) -> str:
        """å¼‚æ­¥æ‰§è¡Œï¼ˆå¯é€‰ï¼‰"""
        raise NotImplementedError("å¼‚æ­¥æ¨¡å¼æœªå®ç°")

# ä½¿ç”¨
tool = KnowledgeBaseSearchTool(kb_name="é‡‘èäº§å“åº“")
result = tool.invoke({"query": "æˆ¿è´·åˆ©ç‡"})
```

**ä¼˜ç‚¹ï¼š**
- âœ… æœ€å¤§çµæ´»æ€§ï¼ˆå¯å®šä¹‰å·¥å…·çŠ¶æ€ã€å¼‚æ­¥æ‰§è¡Œç­‰ï¼‰
- âœ… æ”¯æŒå·¥å…·è‡ªèº«å±æ€§ï¼ˆå¦‚ `kb_name`ï¼‰

**ç¼ºç‚¹ï¼š**
- âŒ ä»£ç æœ€å¤æ‚ï¼ˆéœ€å®ç° `_run` å’Œ `_arun`ï¼‰
- âŒ å¯¹äºç®€å•å·¥å…·è¿‡åº¦è®¾è®¡

---

### 1.4 æœ¬é¡¹ç›®çš„é€‰æ‹©ï¼šStructuredTool

**é€‰æ‹©ç†ç”±ï¼š**

1. **ç±»å‹å®‰å…¨**ï¼šPydantic v2 æä¾›å¼ºå¤§çš„è¿è¡Œæ—¶éªŒè¯
2. **LLM å‹å¥½**ï¼šè¯¦ç»†çš„å‚æ•°æè¿°æé«˜å·¥å…·è°ƒç”¨æˆåŠŸç‡
3. **ä»£ç ç®€æ´**ï¼šç›¸æ¯” BaseTool å‡å°‘ 60% ä»£ç 
4. **ç”Ÿäº§çº§**ï¼šLangChain å®˜æ–¹æ¨èç”¨äºç”Ÿäº§ç¯å¢ƒ

---

## 2. Pydantic v2 å‚æ•°å®šä¹‰è¯¦è§£

### 2.1 ä¸ºä»€ä¹ˆä½¿ç”¨ Pydanticï¼Ÿ

**Pydantic** æ˜¯ Python çš„æ•°æ®éªŒè¯åº“ï¼ŒLangChain 1.x å…¨é¢é‡‡ç”¨ Pydantic v2 ä½œä¸ºç±»å‹ç³»ç»Ÿã€‚

#### **ä¼ ç»Ÿ Python vs Pydantic**

```python
# âŒ ä¼ ç»Ÿ Pythonï¼ˆæ— éªŒè¯ï¼‰
def search(query, kb_name, top_k):
    # é—®é¢˜ï¼š
    # - query å¯èƒ½ä¸æ˜¯å­—ç¬¦ä¸²
    # - top_k å¯èƒ½æ˜¯è´Ÿæ•°
    # - kb_name å¯èƒ½ä¸ºç©º
    pass

# âœ… Pydanticï¼ˆè‡ªåŠ¨éªŒè¯ï¼‰
from pydantic import BaseModel, Field, validator

class SearchParams(BaseModel):
    query: str = Field(min_length=1, description="æŸ¥è¯¢é—®é¢˜")
    kb_name: str = Field(default="default", description="çŸ¥è¯†åº“åç§°")
    top_k: int = Field(default=3, ge=1, le=10, description="è¿”å›ç»“æœæ•°")

    @validator('query')
    def query_not_empty(cls, v):
        if not v.strip():
            raise ValueError("æŸ¥è¯¢ä¸èƒ½ä¸ºç©ºå­—ç¬¦ä¸²")
        return v

# è‡ªåŠ¨éªŒè¯
params = SearchParams(query="  ", kb_name="é‡‘è", top_k=100)
# æŠ¥é”™ï¼š
# ValidationError: query: æŸ¥è¯¢ä¸èƒ½ä¸ºç©ºå­—ç¬¦ä¸²
# ValidationError: top_k: ensure this value is less than or equal to 10
```

---

### 2.2 Field å‚æ•°è¯¦è§£

`Field()` æ˜¯ Pydantic çš„å­—æ®µå®šä¹‰å‡½æ•°ï¼Œç”¨äºæ·»åŠ éªŒè¯è§„åˆ™å’Œå…ƒæ•°æ®ã€‚

#### **å¸¸ç”¨å‚æ•°ï¼š**

```python
from pydantic import BaseModel, Field
from typing import List, Optional

class AdvancedQuery(BaseModel):
    # 1. åŸºç¡€ç±»å‹ + æè¿°
    query: str = Field(
        description="ç”¨æˆ·çš„æŸ¥è¯¢é—®é¢˜"  # LLM å¯è§çš„æè¿°
    )

    # 2. é»˜è®¤å€¼
    kb_name: str = Field(
        default="financial_kb",
        description="çŸ¥è¯†åº“åç§°"
    )

    # 3. æ•°å€¼èŒƒå›´éªŒè¯
    top_k: int = Field(
        default=3,
        ge=1,      # greater than or equal (â‰¥ 1)
        le=10,     # less than or equal (â‰¤ 10)
        description="è¿”å›ç»“æœæ•°é‡ï¼ŒèŒƒå›´1-10"
    )

    # 4. å­—ç¬¦ä¸²é•¿åº¦éªŒè¯
    query_text: str = Field(
        min_length=1,
        max_length=500,
        description="æŸ¥è¯¢æ–‡æœ¬ï¼Œæœ€å¤š500å­—ç¬¦"
    )

    # 5. å¯é€‰å­—æ®µ
    filters: Optional[List[str]] = Field(
        default=None,
        description="è¿‡æ»¤æ¡ä»¶ï¼Œå¯é€‰"
    )

    # 6. æšä¸¾ç±»å‹
    search_type: str = Field(
        default="similarity",
        pattern="^(similarity|mmr|keyword)$",  # æ­£åˆ™éªŒè¯
        description="æ£€ç´¢ç±»å‹ï¼šsimilarityã€mmr æˆ– keyword"
    )
```

---

#### **Field å‚æ•°å®Œæ•´åˆ—è¡¨ï¼š**

| å‚æ•° | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|------|
| `description` | str | å­—æ®µæè¿°ï¼ˆLLM å¯è§ï¼‰ | `"ç”¨æˆ·çš„æŸ¥è¯¢é—®é¢˜"` |
| `default` | Any | é»˜è®¤å€¼ | `default=3` |
| `default_factory` | Callable | é»˜è®¤å€¼å·¥å‚å‡½æ•° | `default_factory=list` |
| `ge` | int/float | å¤§äºç­‰äº | `ge=1` |
| `gt` | int/float | å¤§äº | `gt=0` |
| `le` | int/float | å°äºç­‰äº | `le=10` |
| `lt` | int/float | å°äº | `lt=100` |
| `min_length` | int | æœ€å°é•¿åº¦ï¼ˆå­—ç¬¦ä¸²/åˆ—è¡¨ï¼‰ | `min_length=1` |
| `max_length` | int | æœ€å¤§é•¿åº¦ | `max_length=500` |
| `pattern` | str | æ­£åˆ™è¡¨è¾¾å¼ | `pattern="^\w+$"` |
| `example` | Any | ç¤ºä¾‹å€¼ï¼ˆæ–‡æ¡£ç”¨ï¼‰ | `example="æˆ¿è´·åˆ©ç‡"` |

---

### 2.3 å¤æ‚å‚æ•°ç¤ºä¾‹

#### **åµŒå¥—å¯¹è±¡**

```python
from pydantic import BaseModel, Field
from typing import List

class Filter(BaseModel):
    """è¿‡æ»¤æ¡ä»¶"""
    field: str = Field(description="å­—æ®µå")
    operator: str = Field(description="æ“ä½œç¬¦ï¼šeqã€gtã€lt")
    value: str = Field(description="å€¼")

class ComplexQuery(BaseModel):
    query: str = Field(description="æŸ¥è¯¢é—®é¢˜")
    filters: List[Filter] = Field(
        default=[],
        description="è¿‡æ»¤æ¡ä»¶åˆ—è¡¨"
    )

# LLM è°ƒç”¨ç¤ºä¾‹ï¼š
# {
#   "query": "æˆ¿è´·åˆ©ç‡",
#   "filters": [
#     {"field": "äº§å“ç±»å‹", "operator": "eq", "value": "ä¸ªäººä½æˆ¿è´·æ¬¾"},
#     {"field": "å¹´é™", "operator": "gt", "value": "5"}
#   ]
# }
```

---

#### **æšä¸¾ç±»å‹**

```python
from enum import Enum
from pydantic import BaseModel, Field

class SearchType(str, Enum):
    SIMILARITY = "similarity"
    MMR = "mmr"
    KEYWORD = "keyword"

class TypedQuery(BaseModel):
    query: str = Field(description="æŸ¥è¯¢é—®é¢˜")
    search_type: SearchType = Field(
        default=SearchType.SIMILARITY,
        description="æ£€ç´¢ç±»å‹"
    )

# Pydantic è‡ªåŠ¨éªŒè¯
params = TypedQuery(query="æˆ¿è´·", search_type="invalid")
# æŠ¥é”™ï¼šValidationError: search_type: value is not a valid enumeration member
```

---

## 3. RAG å·¥å…·å®ç°ï¼šnaive_rag_tool.py

### 3.1 å®Œæ•´æºç è§£æ

åœ¨ `tools/naive_rag_tool.py` ä¸­ï¼Œæˆ‘ä»¬å®ç°äº†å®Œæ•´çš„ RAG æ£€ç´¢å·¥å…·ï¼š

```python
import os
import json
from pydantic import BaseModel, Field
from langchain_core.tools import StructuredTool

from utils import get_embedding_model
from app_utils.helpers import to_chroma_collection_name, to_openai_tool_name


def get_naive_rag_tool(vectorstore_name):
    """
    åˆ›å»ºä¸€ä¸ª RAG æ£€ç´¢å·¥å…·ã€‚

    Args:
        vectorstore_name: çŸ¥è¯†åº“åç§°ï¼ˆä¾‹å¦‚ï¼š"financial_products"ï¼‰

    Returns:
        StructuredTool: å¯è¢« LangGraph Agent è°ƒç”¨çš„å·¥å…·
    """

    # ç¬¬1æ­¥ï¼šå®šä¹‰å‚æ•°æ¨¡å‹
    class KBQuery(BaseModel):
        query: str = Field(description="æŸ¥è¯¢å­—ç¬¦ä¸²")

    # ç¬¬2æ­¥ï¼šå®šä¹‰æ‰§è¡Œå‡½æ•°
    def _kb_func(query: str) -> str:
        """
        å•æ¬¡æŸ¥è¯¢æ—¶æŒ‰éœ€å®ä¾‹åŒ–å‘é‡åº“ï¼Œé¿å…é•¿æ—¶é—´æŒæœ‰æŒä¹…è¿æ¥å¯¼è‡´æ–‡ä»¶é”ã€‚
        """
        from langchain_chroma import Chroma

        # åˆ›å»ºå‘é‡åº“è¿æ¥
        vectorstore = Chroma(
            collection_name=to_chroma_collection_name(vectorstore_name),
            embedding_function=get_embedding_model(platform_type="OpenAI"),
            persist_directory=os.path.join(
                os.path.dirname(os.path.dirname(__file__)),
                "kb",
                vectorstore_name,
                "vectorstore"
            ),
        )

        # åˆ›å»ºæ£€ç´¢å™¨
        retriever = vectorstore.as_retriever(
            search_type="similarity_score_threshold",
            search_kwargs={
                "k": 3,
                "score_threshold": 0.15,
            }
        )

        # æ‰§è¡Œæ£€ç´¢
        docs = retriever.invoke(query)

        # æ ¼å¼åŒ–ç»“æœ
        payload = {
            f"å·²çŸ¥å†…å®¹ {inum+1}": doc.page_content.replace(
                doc.metadata.get("source", "") + "\n\n", ""
            )
            for inum, doc in enumerate(docs)
        }

        # è¿”å› JSON å­—ç¬¦ä¸²
        return json.dumps(payload, ensure_ascii=False)

    # ç¬¬3æ­¥ï¼šåˆ›å»ºå·¥å…·
    safe_name = to_openai_tool_name(vectorstore_name)
    return StructuredTool(
        name=f"{safe_name}_knowledge_base_tool",
        description=f"search and return information about {vectorstore_name}",
        args_schema=KBQuery,
        func=_kb_func,
    )
```

---

### 3.2 ä»£ç è¯¦è§£

#### **ç¬¬1éƒ¨åˆ†ï¼šå‚æ•°å®šä¹‰ï¼ˆç¬¬ 16-17 è¡Œï¼‰**

```python
class KBQuery(BaseModel):
    query: str = Field(description="æŸ¥è¯¢å­—ç¬¦ä¸²")
```

**è®¾è®¡è€ƒè™‘ï¼š**

**ä¸ºä»€ä¹ˆåªæœ‰ä¸€ä¸ªå‚æ•°ï¼Ÿ**
- âœ… **ç®€å•ç›´è§‚**ï¼šLLM åªéœ€ä¼ å…¥æŸ¥è¯¢æ–‡æœ¬
- âœ… **é™ä½é”™è¯¯ç‡**ï¼šå‚æ•°è¶Šå¤šï¼ŒLLM è°ƒç”¨é”™è¯¯çš„æ¦‚ç‡è¶Šé«˜
- âœ… **çŸ¥è¯†åº“åç§°éšå¼ç»‘å®š**ï¼šé€šè¿‡é—­åŒ…ï¼ˆ`vectorstore_name`ï¼‰ä¼ å…¥

**è¿›é˜¶ç‰ˆæœ¬ï¼ˆæ”¯æŒå¤šå‚æ•°ï¼‰ï¼š**
```python
class AdvancedKBQuery(BaseModel):
    query: str = Field(description="æŸ¥è¯¢é—®é¢˜")
    top_k: int = Field(default=3, ge=1, le=10, description="è¿”å›ç»“æœæ•°")
    score_threshold: float = Field(default=0.15, ge=0.0, le=1.0, description="ç›¸ä¼¼åº¦é˜ˆå€¼")
```

---

#### **ç¬¬2éƒ¨åˆ†ï¼šæ‰§è¡Œå‡½æ•°ï¼ˆç¬¬ 20-48 è¡Œï¼‰**

##### **å…³é”®è®¾è®¡1ï¼šæŒ‰éœ€å®ä¾‹åŒ–å‘é‡åº“ï¼ˆç¬¬ 21-34 è¡Œï¼‰**

```python
def _kb_func(query: str) -> str:
    """å•æ¬¡æŸ¥è¯¢æ—¶æŒ‰éœ€å®ä¾‹åŒ–å‘é‡åº“ï¼Œé¿å…é•¿æ—¶é—´æŒæœ‰æŒä¹…è¿æ¥å¯¼è‡´æ–‡ä»¶é”ã€‚"""
    from langchain_chroma import Chroma

    vectorstore = Chroma(...)
```

**ä¸ºä»€ä¹ˆä¸åœ¨å·¥å…·åˆ›å»ºæ—¶å°±å®ä¾‹åŒ–ï¼Ÿ**

```python
# âŒ é”™è¯¯æ–¹å¼ï¼šæå‰å®ä¾‹åŒ–
vectorstore = Chroma(...)  # å…¨å±€å˜é‡

def _kb_func(query: str) -> str:
    retriever = vectorstore.as_retriever()
    return retriever.invoke(query)

# é—®é¢˜ï¼š
# 1. é•¿æ—¶é—´æŒæœ‰æ•°æ®åº“è¿æ¥ï¼ˆæ–‡ä»¶é”ï¼‰
# 2. Windows ä¸Šåˆ é™¤çŸ¥è¯†åº“æ—¶ä¼šæŠ¥é”™ï¼šPermissionError
# 3. å¹¶å‘è¯·æ±‚æ—¶å¯èƒ½å†²çª
```

```python
# âœ… æ­£ç¡®æ–¹å¼ï¼šæŒ‰éœ€å®ä¾‹åŒ–
def _kb_func(query: str) -> str:
    vectorstore = Chroma(...)  # æ¯æ¬¡è°ƒç”¨éƒ½åˆ›å»ºæ–°è¿æ¥
    retriever = vectorstore.as_retriever()
    result = retriever.invoke(query)
    # å‡½æ•°ç»“æŸåè‡ªåŠ¨é‡Šæ”¾è¿æ¥
    return result

# ä¼˜åŠ¿ï¼š
# âœ… æ— æ–‡ä»¶é”é—®é¢˜
# âœ… æ”¯æŒå¹¶å‘è°ƒç”¨
# âœ… èµ„æºè‡ªåŠ¨é‡Šæ”¾
```

---

##### **å…³é”®è®¾è®¡2ï¼šç»“æœæ ¼å¼åŒ–ï¼ˆç¬¬ 41-48 è¡Œï¼‰**

```python
# æ‰§è¡Œæ£€ç´¢
docs = retriever.invoke(query)

# æ ¼å¼åŒ–ç»“æœ
payload = {
    f"å·²çŸ¥å†…å®¹ {inum+1}": doc.page_content.replace(
        doc.metadata.get("source", "") + "\n\n", ""
    )
    for inum, doc in enumerate(docs)
}

# è¿”å› JSON å­—ç¬¦ä¸²
return json.dumps(payload, ensure_ascii=False)
```

**ä¸ºä»€ä¹ˆè¿”å› JSON è€Œéçº¯æ–‡æœ¬ï¼Ÿ**

```python
# âŒ æ–¹å¼1ï¼šçº¯æ–‡æœ¬æ‹¼æ¥
def _kb_func_text(query: str) -> str:
    docs = retriever.invoke(query)
    return "\n\n".join([doc.page_content for doc in docs])

# é—®é¢˜ï¼š
# - æ— æ³•åŒºåˆ†å¤šä¸ªæ–‡æ¡£ç‰‡æ®µ
# - LLM éš¾ä»¥å¼•ç”¨å…·ä½“æ¥æº

# âœ… æ–¹å¼2ï¼šç»“æ„åŒ– JSON
def _kb_func_json(query: str) -> str:
    docs = retriever.invoke(query)
    payload = {f"å·²çŸ¥å†…å®¹ {i+1}": doc.page_content for i, doc in enumerate(docs)}
    return json.dumps(payload, ensure_ascii=False)

# ä¼˜åŠ¿ï¼š
# âœ… æ¸…æ™°çš„æ–‡æ¡£åˆ†éš”
# âœ… LLM å¯å¼•ç”¨"å·²çŸ¥å†…å®¹ 1"ã€"å·²çŸ¥å†…å®¹ 2"
# âœ… æ–¹ä¾¿åç»­å¤„ç†ï¼ˆè§£æã€è¿‡æ»¤ç­‰ï¼‰
```

**å®é™…è¾“å‡ºç¤ºä¾‹ï¼š**

```json
{
  "å·²çŸ¥å†…å®¹ 1": "ä¸ªäººä½æˆ¿è´·æ¬¾åˆ©ç‡ä¸ºLPR+0.5%ï¼Œé¦–å¥—æˆ¿å¯äº«å—LPR+0.3%çš„ä¼˜æƒ ...",
  "å·²çŸ¥å†…å®¹ 2": "è´·æ¬¾æœŸé™æœ€é•¿30å¹´ï¼Œå¹´é¾„+è´·æ¬¾æœŸé™â‰¤70å²...",
  "å·²çŸ¥å†…å®¹ 3": "éœ€æä¾›èº«ä»½è¯ã€æ”¶å…¥è¯æ˜ã€è´­æˆ¿åˆåŒç­‰ææ–™..."
}
```

**LLM åŸºäºæ­¤ç”Ÿæˆçš„å›ç­”ï¼š**
```
æ ¹æ®ã€å·²çŸ¥å†…å®¹ 1ã€‘ï¼Œæˆ‘è¡Œä¸ªäººä½æˆ¿è´·æ¬¾åˆ©ç‡ä¸ºLPR+0.5%ï¼Œé¦–å¥—æˆ¿å¯äº«å—
LPR+0.3%çš„ä¼˜æƒ åˆ©ç‡ã€‚åŒæ—¶ï¼Œæ ¹æ®ã€å·²çŸ¥å†…å®¹ 2ã€‘ï¼Œè´·æ¬¾æœŸé™æœ€é•¿ä¸º30å¹´ã€‚
```

---

##### **å…³é”®è®¾è®¡3ï¼šç§»é™¤æ–‡ä»¶è·¯å¾„ï¼ˆç¬¬ 44 è¡Œï¼‰**

```python
doc.page_content.replace(doc.metadata.get("source", "") + "\n\n", "")
```

**ä¸ºä»€ä¹ˆè¦ç§»é™¤ï¼Ÿ**

å›é¡¾ç¬¬04ç« ï¼Œæˆ‘ä»¬åœ¨æ–‡æ¡£åˆ†å—æ—¶æ·»åŠ äº†å…ƒæ•°æ®ï¼š

```python
# ç¬¬04ç« çš„ä»£ç 
for doc in doc_splits:
    doc.page_content = doc.metadata["source"] + "\n\n" + doc.page_content

# ç»“æœï¼š
# "kb/financial_kb/files/äº§å“æ‰‹å†Œ.md\n\nä¸ªäººä½æˆ¿è´·æ¬¾åˆ©ç‡ä¸º..."
```

**å¦‚æœä¸ç§»é™¤ï¼š**

```json
{
  "å·²çŸ¥å†…å®¹ 1": "kb/financial_kb/files/äº§å“æ‰‹å†Œ.md\n\nä¸ªäººä½æˆ¿è´·æ¬¾åˆ©ç‡ä¸º...",
  "å·²çŸ¥å†…å®¹ 2": "kb/financial_kb/files/äº§å“æ‰‹å†Œ.md\n\nè´·æ¬¾æœŸé™æœ€é•¿30å¹´..."
}
```

**é—®é¢˜ï¼š**
- âŒ é‡å¤çš„æ–‡ä»¶è·¯å¾„å ç”¨ LLM ä¸Šä¸‹æ–‡
- âŒ ç”¨æˆ·çœ‹åˆ°å†…éƒ¨è·¯å¾„ï¼ˆä½“éªŒå·®ï¼‰
- âŒ å¢åŠ  token æ¶ˆè€—

**ç§»é™¤åï¼š**

```json
{
  "å·²çŸ¥å†…å®¹ 1": "ä¸ªäººä½æˆ¿è´·æ¬¾åˆ©ç‡ä¸º...",
  "å·²çŸ¥å†…å®¹ 2": "è´·æ¬¾æœŸé™æœ€é•¿30å¹´..."
}
```

**æ”¹è¿›æ–¹æ¡ˆï¼š** å¦‚éœ€ä¿ç•™æ¥æºä¿¡æ¯ï¼Œå¯å•ç‹¬æå–ï¼š

```python
payload = {
    f"å·²çŸ¥å†…å®¹ {inum+1}": {
        "content": doc.page_content.replace(doc.metadata.get("source", "") + "\n\n", ""),
        "source": os.path.basename(doc.metadata.get("source", "æœªçŸ¥"))
    }
    for inum, doc in enumerate(docs)
}

# è¾“å‡ºï¼š
# {
#   "å·²çŸ¥å†…å®¹ 1": {
#     "content": "ä¸ªäººä½æˆ¿è´·æ¬¾åˆ©ç‡ä¸º...",
#     "source": "äº§å“æ‰‹å†Œ.md"
#   }
# }
```

---

#### **ç¬¬3éƒ¨åˆ†ï¼šå·¥å…·åç§°è½¬æ¢ï¼ˆç¬¬ 51-56 è¡Œï¼‰**

```python
safe_name = to_openai_tool_name(vectorstore_name)
return StructuredTool(
    name=f"{safe_name}_knowledge_base_tool",
    description=f"search and return information about {vectorstore_name}",
    args_schema=KBQuery,
    func=_kb_func,
)
```

**ä¸ºä»€ä¹ˆéœ€è¦ `to_openai_tool_name()`ï¼Ÿ**

OpenAI Function Calling å¯¹å·¥å…·åç§°æœ‰ä¸¥æ ¼é™åˆ¶ï¼š
- å¿…é¡»ä»¥å­—æ¯æˆ–æ•°å­—å¼€å¤´
- åªèƒ½åŒ…å« `a-zA-Z0-9_`
- é•¿åº¦ä¸è¶…è¿‡ 64 å­—ç¬¦

**ç¤ºä¾‹ï¼š**

```python
# åœ¨ app_utils/helpers.py ä¸­
def to_openai_tool_name(name: str) -> str:
    s = re.sub(r"[^a-zA-Z0-9_]+", "_", name)
    s = re.sub(r"^([^a-zA-Z0-9_])+", "", s)
    s = re.sub(r"([^a-zA-Z0-9_])+$", "", s)
    if len(s) < 3:
        base = re.sub(r"[^a-zA-Z0-9_]", "", name)
        s = base if len(base) >= 3 else f"kb_{abs(hash(name))%100000}"
    return s[:64]

# æµ‹è¯•
to_openai_tool_name("é‡‘èçŸ¥è¯†åº“")         # â†’ "kb_12345"
to_openai_tool_name("financial_products") # â†’ "financial_products"
to_openai_tool_name("äº§å“-v2.0!")         # â†’ "v2_0"
```

---

### 3.3 å·¥å…·è°ƒç”¨ç¤ºä¾‹

#### **ç›´æ¥è°ƒç”¨**

```python
# åˆ›å»ºå·¥å…·
from tools.naive_rag_tool import get_naive_rag_tool

tool = get_naive_rag_tool("financial_products")

# è°ƒç”¨å·¥å…·
result = tool.invoke({"query": "æˆ¿è´·åˆ©ç‡æ˜¯å¤šå°‘ï¼Ÿ"})
print(result)

# è¾“å‡ºï¼ˆJSON å­—ç¬¦ä¸²ï¼‰ï¼š
# {
#   "å·²çŸ¥å†…å®¹ 1": "ä¸ªäººä½æˆ¿è´·æ¬¾åˆ©ç‡ä¸ºLPR+0.5%...",
#   "å·²çŸ¥å†…å®¹ 2": "é¦–å¥—æˆ¿å¯äº«å—LPR+0.3%çš„ä¼˜æƒ åˆ©ç‡..."
# }
```

---

#### **LangGraph Agent è°ƒç”¨**

```python
# åœ¨ Agent ä¸­ä½¿ç”¨ï¼ˆç¬¬06ç« è¯¦è§£ï¼‰
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4o-mini")
tools = [get_naive_rag_tool("financial_products")]

agent = create_react_agent(llm, tools)

# ç”¨æˆ·æé—®
response = agent.invoke({
    "messages": [{"role": "user", "content": "2024å¹´æˆ¿è´·åˆ©ç‡æ˜¯å¤šå°‘ï¼Ÿ"}]
})

# Agent æ‰§è¡Œæµç¨‹ï¼š
# 1. LLM è¯†åˆ«éœ€è¦è°ƒç”¨ financial_products_knowledge_base_tool
# 2. ç”Ÿæˆè°ƒç”¨è¯·æ±‚ï¼š{"query": "2024å¹´æˆ¿è´·åˆ©ç‡"}
# 3. å·¥å…·è¿”å›æ£€ç´¢ç»“æœï¼ˆJSONï¼‰
# 4. LLM åŸºäºç»“æœç”Ÿæˆå›ç­”
```

---

## 4. LLM å®¢æˆ·ç«¯å°è£…ï¼šllm_client.py

### 4.1 ä¸ºä»€ä¹ˆéœ€è¦å°è£…ï¼Ÿ

åœ¨ä¼ä¸šçº§é¡¹ç›®ä¸­ï¼Œç›´æ¥ä½¿ç”¨ `ChatOpenAI` ä¼šå¯¼è‡´é…ç½®åˆ†æ•£ï¼š

```python
# âŒ åé¢æ¡ˆä¾‹ï¼šé…ç½®åˆ†æ•£
# æ–‡ä»¶1ï¼šwebui/chat_page.py
llm = ChatOpenAI(
    base_url=os.getenv("OPENAI_BASE_URL"),
    api_key=os.getenv("OPENAI_API_KEY"),
    model="gpt-4o-mini",
    temperature=0.1,
    streaming=True
)

# æ–‡ä»¶2ï¼šcore/rag_workflow.py
llm = ChatOpenAI(
    base_url=os.getenv("OPENAI_BASE_URL"),  # é‡å¤é…ç½®
    api_key=os.getenv("OPENAI_API_KEY"),    # é‡å¤é…ç½®
    model="gpt-4o-mini",                     # ç¡¬ç¼–ç 
    temperature=0.1,
    streaming=True
)

# é—®é¢˜ï¼š
# 1. é…ç½®é‡å¤ï¼ˆè¿å DRY åŸåˆ™ï¼‰
# 2. ä¿®æ”¹é…ç½®éœ€è¦æ”¹å¤šå¤„
# 3. æµ‹è¯•å›°éš¾ï¼ˆéš¾ä»¥ mockï¼‰
```

---

### 4.2 å®Œæ•´æºç è§£æ

åœ¨ `core/llm_client.py` ä¸­ï¼š

```python
from typing import Any, List, Optional
from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage
from app_utils.config import get_settings, Settings


def _build_llm(settings: Settings) -> ChatOpenAI:
    """
    æ„å»ºå¹¶è¿”å›ç»Ÿä¸€çš„ ChatOpenAI å®¢æˆ·ç«¯ã€‚
    è¦æ±‚é€šè¿‡ç¯å¢ƒå˜é‡å®‰å…¨æ³¨å…¥ base_url ä¸ api_keyã€‚
    """
    return ChatOpenAI(
        base_url=settings.base_url,
        api_key=settings.api_key,
        model_name=settings.model,
        streaming=True,
        temperature=0.1,
    )


class LLMClient:
    """
    ç»Ÿä¸€çš„ LLM è°ƒç”¨å°è£…ï¼Œæä¾›ç®€å•çš„ invoke æ¥å£ã€‚
    """

    def __init__(self, settings: Optional[Settings] = None) -> None:
        settings = settings or get_settings()
        self.llm = _build_llm(settings)

    def invoke(self, messages: List[BaseMessage]) -> Any:
        """
        è°ƒç”¨åº•å±‚ LLMï¼Œè¿”å›æ¨¡å‹å“åº”ã€‚
        """
        return self.llm.invoke(messages)
```

---

### 4.3 ä»£ç è¯¦è§£

#### **ç¬¬1éƒ¨åˆ†ï¼šLLM æ„å»ºå‡½æ•°ï¼ˆç¬¬ 7-18 è¡Œï¼‰**

```python
def _build_llm(settings: Settings) -> ChatOpenAI:
    """æ„å»ºå¹¶è¿”å›ç»Ÿä¸€çš„ ChatOpenAI å®¢æˆ·ç«¯ã€‚"""
    return ChatOpenAI(
        base_url=settings.base_url,
        api_key=settings.api_key,
        model_name=settings.model,
        streaming=True,
        temperature=0.1,
    )
```

**å‚æ•°è¯´æ˜ï¼š**

1. **streaming=True**

   **ä½œç”¨**ï¼šå¯ç”¨æµå¼è¾“å‡ºï¼ˆServer-Sent Eventsï¼‰

   **æ•ˆæœå¯¹æ¯”ï¼š**

   ```python
   # streaming=Falseï¼ˆé»˜è®¤ï¼‰
   response = llm.invoke("å†™ä¸€ç¯‡500å­—çš„æ–‡ç« ")
   print(response.content)
   # ç­‰å¾…10ç§’... ç„¶åä¸€æ¬¡æ€§è¾“å‡ºå…¨éƒ¨å†…å®¹

   # streaming=True
   for chunk in llm.stream("å†™ä¸€ç¯‡500å­—çš„æ–‡ç« "):
       print(chunk.content, end="")
   # é€å­—è¾“å‡ºï¼šå¤§å®¶å¥½... ä»Šå¤©... æˆ‘ä»¬... æ¥èŠ...
   ```

   **ä¸ºä»€ä¹ˆå¯ç”¨æµå¼ï¼Ÿ**
   - âœ… **ç”¨æˆ·ä½“éªŒå¥½**ï¼šå®æ—¶çœ‹åˆ°ç”Ÿæˆè¿‡ç¨‹ï¼ˆç±»ä¼¼ ChatGPTï¼‰
   - âœ… **å‡å°‘ç­‰å¾…æ„ŸçŸ¥**ï¼šç”¨æˆ·ä¸ä¼šè§‰å¾—ç³»ç»Ÿå¡æ­»
   - âœ… **æå‰å‘ç°é—®é¢˜**ï¼šå¦‚æœç”Ÿæˆæ–¹å‘é”™è¯¯ï¼Œå¯æå‰ä¸­æ–­

2. **temperature=0.1**

   **ä½œç”¨**ï¼šæ§åˆ¶ç”Ÿæˆçš„éšæœºæ€§

   | temperature | æ•ˆæœ | é€‚ç”¨åœºæ™¯ |
   |-------------|------|----------|
   | 0.0 | å®Œå…¨ç¡®å®šæ€§ï¼ˆæ¯æ¬¡ç›¸åŒï¼‰ | å®¢æœã€ç¿»è¯‘ã€ä»£ç ç”Ÿæˆ |
   | **0.1** | **å¾®å¼±éšæœºæ€§ï¼ˆæ¨èï¼‰** | **RAG é—®ç­”ï¼ˆæœ¬é¡¹ç›®ï¼‰** |
   | 0.7 | å¹³è¡¡ | é€šç”¨å¯¹è¯ |
   | 1.0+ | é«˜åˆ›é€ æ€§ | åˆ›æ„å†™ä½œã€å¤´è„‘é£æš´ |

   **ä¸ºä»€ä¹ˆé€‰æ‹© 0.1ï¼Ÿ**
   - âœ… ä¿è¯å›ç­”ç¨³å®šæ€§ï¼ˆåŸºäºæ£€ç´¢ç»“æœçš„å›ç­”åº”è¯¥ä¸€è‡´ï¼‰
   - âœ… å…è®¸å¾®å°å˜åŒ–ï¼ˆé¿å…æœºæ¢°åŒ–å›ç­”ï¼‰

---

#### **ç¬¬2éƒ¨åˆ†ï¼šLLMClient ç±»ï¼ˆç¬¬ 21-34 è¡Œï¼‰**

```python
class LLMClient:
    """ç»Ÿä¸€çš„ LLM è°ƒç”¨å°è£…ï¼Œæä¾›ç®€å•çš„ invoke æ¥å£ã€‚"""

    def __init__(self, settings: Optional[Settings] = None) -> None:
        settings = settings or get_settings()
        self.llm = _build_llm(settings)

    def invoke(self, messages: List[BaseMessage]) -> Any:
        """è°ƒç”¨åº•å±‚ LLMï¼Œè¿”å›æ¨¡å‹å“åº”ã€‚"""
        return self.llm.invoke(messages)
```

**è®¾è®¡æ¨¡å¼ï¼šé—¨é¢æ¨¡å¼ï¼ˆFacade Patternï¼‰**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LLMClientï¼ˆé—¨é¢ï¼‰                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ - éšè—åº•å±‚å¤æ‚æ€§                            â”‚ â”‚
â”‚  â”‚ - æä¾›ç»Ÿä¸€æ¥å£                              â”‚ â”‚
â”‚  â”‚ - æ–¹ä¾¿æ›¿æ¢å®ç°ï¼ˆå¦‚åˆ‡æ¢åˆ° Ollamaï¼‰          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€ ChatOpenAI
           â”œâ”€â”€ é…ç½®ç®¡ç†ï¼ˆSettingsï¼‰
           â””â”€â”€ é”™è¯¯å¤„ç†ï¼ˆæœªæ¥æ‰©å±•ï¼‰
```

**å¥½å¤„ï¼š**

1. **ç»Ÿä¸€æ¥å£**
   ```python
   # æ‰€æœ‰åœ°æ–¹éƒ½è¿™æ ·è°ƒç”¨
   from core.llm_client import LLMClient
   client = LLMClient()
   response = client.invoke(messages)
   ```

2. **æ˜“äºæ›¿æ¢**
   ```python
   # å°†æ¥åˆ‡æ¢åˆ° Ollamaï¼Œåªéœ€ä¿®æ”¹ _build_llm()
   def _build_llm(settings: Settings):
       return ChatOllama(  # åªæ”¹è¿™ä¸€å¤„
           model=settings.model,
           base_url=settings.base_url
       )
   ```

3. **æ˜“äºæ‰©å±•**
   ```python
   class LLMClient:
       def invoke(self, messages: List[BaseMessage]) -> Any:
           try:
               return self.llm.invoke(messages)
           except RateLimitError:
               # è‡ªåŠ¨é‡è¯•é€»è¾‘
               time.sleep(1)
               return self.llm.invoke(messages)
   ```

---

### 4.4 ä½¿ç”¨ç¤ºä¾‹

```python
from core.llm_client import LLMClient
from langchain_core.messages import HumanMessage, SystemMessage

# åˆ›å»ºå®¢æˆ·ç«¯
client = LLMClient()

# æ–¹å¼1ï¼šç®€å•å¯¹è¯
messages = [
    HumanMessage(content="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ ä»¬çš„æˆ¿è´·äº§å“")
]
response = client.invoke(messages)
print(response.content)

# æ–¹å¼2ï¼šå¸¦ç³»ç»Ÿæç¤ºè¯
messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡‘èå®¢æœï¼Œè¯·åŸºäºæä¾›çš„çŸ¥è¯†åº“å›ç­”é—®é¢˜ã€‚"),
    HumanMessage(content="æˆ¿è´·åˆ©ç‡æ˜¯å¤šå°‘ï¼Ÿ")
]
response = client.invoke(messages)
print(response.content)

# æ–¹å¼3ï¼šå¤šè½®å¯¹è¯
messages = [
    HumanMessage(content="æˆ¿è´·åˆ©ç‡æ˜¯å¤šå°‘ï¼Ÿ"),
    AIMessage(content="å½“å‰æˆ¿è´·åˆ©ç‡ä¸ºLPR+0.5%..."),
    HumanMessage(content="é¦–ä»˜æ¯”ä¾‹å‘¢ï¼Ÿ")
]
response = client.invoke(messages)
print(response.content)
```

---

## 5. å·¥å…·è°ƒç”¨çš„åº•å±‚æœºåˆ¶ï¼šOpenAI Function Calling

### 5.1 ä»€ä¹ˆæ˜¯ Function Callingï¼Ÿ

**Function Calling** æ˜¯ OpenAI åœ¨ GPT-3.5/4 ä¸­å¼•å…¥çš„ç‰¹æ€§ï¼Œå…è®¸ LLM ç”Ÿæˆç»“æ„åŒ–çš„å‡½æ•°è°ƒç”¨è¯·æ±‚ã€‚

#### **ä¼ ç»Ÿ Prompt vs Function Calling**

```python
# âŒ ä¼ ç»Ÿæ–¹å¼ï¼šè‡ªç„¶è¯­è¨€æŒ‡ä»¤
prompt = """
ä½ æœ‰ä¸€ä¸ªå·¥å…·å« search_knowledge_baseï¼Œå¯ä»¥æœç´¢çŸ¥è¯†åº“ã€‚
å½“ç”¨æˆ·é—®äº§å“ç›¸å…³é—®é¢˜æ—¶ï¼Œè¯·è°ƒç”¨è¿™ä¸ªå·¥å…·ã€‚

æ ¼å¼ï¼šTOOL: search_knowledge_base(query="...")

ç”¨æˆ·ï¼šæˆ¿è´·åˆ©ç‡æ˜¯å¤šå°‘ï¼Ÿ
"""

response = llm.invoke(prompt)
print(response.content)
# è¾“å‡ºï¼šTOOL: search_knowledge_base(query="æˆ¿è´·åˆ©ç‡")
# é—®é¢˜ï¼š
# 1. æ ¼å¼ä¸ç¨³å®šï¼ˆå¯èƒ½è¾“å‡º "Tool:" æˆ– "TOOL:" æˆ– "å·¥å…·ï¼š"ï¼‰
# 2. éœ€è¦æ‰‹åŠ¨è§£æå­—ç¬¦ä¸²
# 3. å®¹æ˜“å‡ºé”™ï¼ˆå¼•å·ã€æ‹¬å·ä¸åŒ¹é…ï¼‰
```

```python
# âœ… Function Callingï¼šç»“æ„åŒ–è¾“å‡º
tools = [
    {
        "type": "function",
        "function": {
            "name": "search_knowledge_base",
            "description": "æœç´¢é‡‘èçŸ¥è¯†åº“è·å–äº§å“ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "ç”¨æˆ·çš„æŸ¥è¯¢é—®é¢˜"
                    }
                },
                "required": ["query"]
            }
        }
    }
]

response = llm.invoke(
    [HumanMessage(content="æˆ¿è´·åˆ©ç‡æ˜¯å¤šå°‘ï¼Ÿ")],
    tools=tools
)

print(response.tool_calls)
# è¾“å‡ºï¼ˆç»“æ„åŒ–ï¼‰ï¼š
# [
#   {
#     "name": "search_knowledge_base",
#     "args": {"query": "æˆ¿è´·åˆ©ç‡"}
#   }
# ]
```

---

### 5.2 LangChain çš„ bind_tools() å°è£…

åœ¨ LangChain ä¸­ï¼Œ`bind_tools()` è‡ªåŠ¨å°†å·¥å…·è½¬æ¢ä¸º OpenAI Function Calling æ ¼å¼ï¼š

```python
from langchain_openai import ChatOpenAI
from tools.naive_rag_tool import get_naive_rag_tool

# åˆ›å»º LLM å’Œå·¥å…·
llm = ChatOpenAI(model="gpt-4o-mini")
tools = [get_naive_rag_tool("financial_products")]

# ç»‘å®šå·¥å…·
llm_with_tools = llm.bind_tools(tools)

# è°ƒç”¨
response = llm_with_tools.invoke([
    HumanMessage(content="æˆ¿è´·åˆ©ç‡æ˜¯å¤šå°‘ï¼Ÿ")
])

# æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
if response.tool_calls:
    tool_call = response.tool_calls[0]
    print(f"å·¥å…·åç§°: {tool_call['name']}")
    print(f"å‚æ•°: {tool_call['args']}")

    # æ‰§è¡Œå·¥å…·
    tool = tools[0]
    result = tool.invoke(tool_call['args'])
    print(f"å·¥å…·ç»“æœ: {result}")
```

---

### 5.3 å®Œæ•´è°ƒç”¨æµç¨‹å›¾

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant Agent as LangGraph Agent
    participant LLM as OpenAI LLM
    participant Tool as RAG Tool
    participant VectorDB as ChromaDB

    User->>Agent: "æˆ¿è´·åˆ©ç‡æ˜¯å¤šå°‘ï¼Ÿ"

    Agent->>LLM: å‘é€æ¶ˆæ¯ + å·¥å…·å®šä¹‰
    Note right of LLM: åˆ†æï¼šéœ€è¦è°ƒç”¨å·¥å…·

    LLM-->>Agent: è¿”å›å·¥å…·è°ƒç”¨è¯·æ±‚<br/>{name: "financial_products_kb_tool",<br/>args: {"query": "æˆ¿è´·åˆ©ç‡"}}

    Agent->>Tool: invoke({"query": "æˆ¿è´·åˆ©ç‡"})

    Tool->>VectorDB: å‘é‡æ£€ç´¢
    VectorDB-->>Tool: è¿”å›ç›¸å…³æ–‡æ¡£

    Tool-->>Agent: è¿”å› JSON ç»“æœ<br/>{"å·²çŸ¥å†…å®¹ 1": "...", "å·²çŸ¥å†…å®¹ 2": "..."}

    Agent->>LLM: å‘é€å·¥å…·ç»“æœ
    Note right of LLM: åŸºäºç»“æœç”Ÿæˆå›ç­”

    LLM-->>Agent: "æ ¹æ®æˆ‘è¡Œäº§å“æ‰‹å†Œï¼Œæˆ¿è´·åˆ©ç‡ä¸º..."

    Agent-->>User: æ˜¾ç¤ºæœ€ç»ˆå›ç­”
```

---

## 6. è¿›é˜¶ï¼šå¤šå·¥å…·åä½œç¤ºä¾‹

### 6.1 åœºæ™¯ï¼šé‡‘èå®¢æœå¤šæŠ€èƒ½

```python
from tools.naive_rag_tool import get_naive_rag_tool
from langchain_core.tools import tool
from datetime import datetime

# å·¥å…·1ï¼šçŸ¥è¯†åº“æ£€ç´¢
kb_tool = get_naive_rag_tool("financial_products")

# å·¥å…·2ï¼šè®¡ç®—è´·æ¬¾æœˆä¾›
@tool
def calculate_mortgage(
    principal: float,
    annual_rate: float,
    years: int
) -> str:
    """
    è®¡ç®—ç­‰é¢æœ¬æ¯è´·æ¬¾æœˆä¾›ã€‚

    Args:
        principal: è´·æ¬¾æœ¬é‡‘ï¼ˆå…ƒï¼‰
        annual_rate: å¹´åˆ©ç‡ï¼ˆä¾‹å¦‚ï¼š4.5 è¡¨ç¤º 4.5%ï¼‰
        years: è´·æ¬¾å¹´é™
    """
    monthly_rate = annual_rate / 100 / 12
    months = years * 12
    monthly_payment = (
        principal * monthly_rate * (1 + monthly_rate)**months /
        ((1 + monthly_rate)**months - 1)
    )
    return f"æœˆä¾›ï¼š{monthly_payment:.2f}å…ƒ"

# å·¥å…·3ï¼šæŸ¥è¯¢å½“å‰æ—¶é—´
@tool
def get_current_time() -> str:
    """è·å–å½“å‰æ—¶é—´"""
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# ç»„åˆå·¥å…·
tools = [kb_tool, calculate_mortgage, get_current_time]
```

---

### 6.2 Agent è‡ªåŠ¨é€‰æ‹©å·¥å…·

```python
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4o-mini")
agent = create_react_agent(llm, tools)

# åœºæ™¯1ï¼šåªéœ€çŸ¥è¯†åº“
response = agent.invoke({
    "messages": [{"role": "user", "content": "æˆ¿è´·åˆ©ç‡æ˜¯å¤šå°‘ï¼Ÿ"}]
})
# Agent è‡ªåŠ¨è°ƒç”¨ï¼škb_tool("æˆ¿è´·åˆ©ç‡")

# åœºæ™¯2ï¼šéœ€è¦çŸ¥è¯†åº“ + è®¡ç®—
response = agent.invoke({
    "messages": [{
        "role": "user",
        "content": "æˆ‘æƒ³è´·æ¬¾100ä¸‡ï¼Œ30å¹´ï¼Œå¸®æˆ‘ç®—ä¸€ä¸‹æœˆä¾›"
    }]
})
# Agent è‡ªåŠ¨è°ƒç”¨ï¼š
# 1. kb_tool("æˆ¿è´·åˆ©ç‡") â†’ è·å–åˆ©ç‡ 4.5%
# 2. calculate_mortgage(1000000, 4.5, 30) â†’ è®¡ç®—æœˆä¾›

# åœºæ™¯3ï¼šéœ€è¦æ—¶é—´ä¿¡æ¯
response = agent.invoke({
    "messages": [{
        "role": "user",
        "content": "ç°åœ¨å‡ ç‚¹äº†ï¼Ÿä»Šå¤©èƒ½åŠç†è´·æ¬¾ä¸šåŠ¡å—ï¼Ÿ"
    }]
})
# Agent è‡ªåŠ¨è°ƒç”¨ï¼š
# 1. get_current_time() â†’ è·å–å½“å‰æ—¶é—´
# 2. kb_tool("è¥ä¸šæ—¶é—´") â†’ æŸ¥è¯¢è¥ä¸šæ—¶é—´
```

---

## 7. æœ¬ç« æ€»ç»“ä¸ä¸‹ä¸€æ­¥

### 7.1 æœ¬ç« æ”¶è·

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œæˆ‘ä»¬å®Œæˆäº†ï¼š

âœ… **ç†è®ºæŒæ¡**
- ç†è§£ LangChain å·¥å…·ä½“ç³»æ¶æ„
- æŒæ¡ StructuredTool vs @tool vs BaseTool çš„é€‰æ‹©
- ç†è§£ OpenAI Function Calling æœºåˆ¶
- æŒæ¡ Pydantic v2 å‚æ•°å®šä¹‰

âœ… **æŠ€æœ¯å®ç°**
- å®ç° RAG æ£€ç´¢å·¥å…·ï¼ˆ`naive_rag_tool.py`ï¼‰
- å®ç° LLM å®¢æˆ·ç«¯å°è£…ï¼ˆ`llm_client.py`ï¼‰
- æŒæ¡å·¥å…·åç§°è½¬æ¢ä¸å‚æ•°éªŒè¯
- ç†è§£æŒ‰éœ€å®ä¾‹åŒ–é¿å…æ–‡ä»¶é”

âœ… **å·¥ç¨‹å®è·µ**
- é—¨é¢æ¨¡å¼å°è£… LLM å®¢æˆ·ç«¯
- ç»“æ„åŒ– JSON è¾“å‡ºæå‡ LLM å‡†ç¡®åº¦
- å¤šå·¥å…·åä½œè®¾è®¡

---

### 7.2 å…³é”®æŠ€æœ¯å›é¡¾

| æŠ€æœ¯ç‚¹ | ä¼ ç»Ÿæ–¹å¼ | æœ¬é¡¹ç›®æ–¹æ¡ˆ | æå‡ |
|--------|----------|------------|------|
| å·¥å…·å®šä¹‰ | @tool è£…é¥°å™¨ | **StructuredTool + Pydantic** | ç±»å‹å®‰å…¨ âœ… |
| å‚æ•°éªŒè¯ | æ‰‹åŠ¨æ£€æŸ¥ | **Field() è‡ªåŠ¨éªŒè¯** | é›¶é”™è¯¯ âœ… |
| LLM é…ç½® | åˆ†æ•£åœ¨å„å¤„ | **LLMClient ç»Ÿä¸€å°è£…** | ç»´æŠ¤æ€§ â†‘90% |
| å·¥å…·è°ƒç”¨ | å­—ç¬¦ä¸²è§£æ | **OpenAI Function Calling** | å‡†ç¡®ç‡ â†‘95% |

---

### 7.3 ä¸‹ä¸€ç« é¢„å‘Š

**ç¬¬ 06 ç« ï¼šRAG å·¥ä½œæµå®ç° - æ‰“é€ ä¼šæ£€ç´¢çš„æ™ºèƒ½å®¢æœ Agent**

æˆ‘ä»¬å°†å­¦ä¹ ï¼š
- ğŸ”„ **LangGraph å·¥ä½œæµ**ï¼šStateGraph + MessagesState + ToolNode
- ğŸ¯ **ReAct æ¨¡å¼**ï¼šReasoning + Acting å¾ªç¯
- ğŸ§  **Agent èŠ‚ç‚¹è®¾è®¡**ï¼šcall_model + tool_node
- ğŸ”€ **æ¡ä»¶è·¯ç”±**ï¼štools_condition è‡ªåŠ¨åˆ¤æ–­
- ğŸ’¾ **æ£€æŸ¥ç‚¹ç®¡ç†**ï¼šMemorySaver å®ç°å¤šè½®å¯¹è¯
- ğŸ“Š **å®Œæ•´å®ç°**ï¼š`rag_workflow.py` è¯¦è§£

**æ ¸å¿ƒä»£ç é¢„è§ˆï¼š**

```python
# ç¬¬ 06 ç« å°†å®ç°
from langgraph.graph import StateGraph, MessagesState
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.checkpoint.memory import MemorySaver

def build_rag_graph(tools):
    # å®šä¹‰å·¥ä½œæµ
    workflow = StateGraph(MessagesState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("agent", call_model)      # LLM èŠ‚ç‚¹
    workflow.add_node("tools", ToolNode(tools)) # å·¥å…·èŠ‚ç‚¹

    # æ·»åŠ è¾¹
    workflow.add_conditional_edges("agent", tools_condition)
    workflow.add_edge("tools", "agent")
    workflow.set_entry_point("agent")

    # ç¼–è¯‘å¹¶å¯ç”¨æ£€æŸ¥ç‚¹
    return workflow.compile(checkpointer=MemorySaver())
```

---

**ç‰ˆæœ¬ä¿¡æ¯**
- **æ–‡æ¡£ç‰ˆæœ¬**: v1.0
- **æœ€åæ›´æ–°**: 2025-01-16
- **é€‚é…é¡¹ç›®ç‰ˆæœ¬**: langgraph-rag v0.1.0
- **ä½œè€…**: LangGraph-RAG Tutorial Team
